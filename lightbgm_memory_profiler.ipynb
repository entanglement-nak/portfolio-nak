{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNbDRPp4TREZKeRxfrhyCEd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/entanglement-nak/portfolio-nak/blob/main/lightbgm_memory_profiler.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hRMbAOM5OJi1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "323a8d08-0d51-405b-a8ad-c086fed5fdbe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting memory_profiler\n",
            "  Downloading memory_profiler-0.61.0-py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from memory_profiler) (5.9.5)\n",
            "Installing collected packages: memory_profiler\n",
            "Successfully installed memory_profiler-0.61.0\n"
          ]
        }
      ],
      "source": [
        "pip install memory_profiler"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from memory_profiler import profile\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import lightgbm as lgb\n",
        "from sklearn.metrics import classification_report, accuracy_score, f1_score, matthews_corrcoef\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import resample\n",
        "import time"
      ],
      "metadata": {
        "id": "c4jtKYBVORmQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext memory_profiler"
      ],
      "metadata": {
        "id": "NT_pBDiOU1el"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "kqe5xraNPVpr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6bb1e7b-6317-407d-8956-65a60ee6a362"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# データの読み込み\n",
        "def load_data(train_path, test_path):\n",
        "    train_df = pd.read_excel(train_path, header=None)\n",
        "    test_df = pd.read_excel(test_path, header=None)\n",
        "    return train_df, test_df"
      ],
      "metadata": {
        "id": "VkJthDFhOUUQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# データの前処理\n",
        "def preprocess_data(train_df, test_df):\n",
        "    combined_data = pd.concat([train_df, test_df], axis=0)\n",
        "    combined_data_filled = combined_data.fillna(combined_data.mean())\n",
        "    combined_data_cleaned = combined_data_filled.replace([np.inf, -np.inf], np.nan).fillna(combined_data_filled.mean())\n",
        "    X = combined_data_cleaned.drop(combined_data_cleaned.columns[0], axis=1)\n",
        "    y = combined_data_cleaned[combined_data_cleaned.columns[0]]\n",
        "    return X, y"
      ],
      "metadata": {
        "id": "g4_3PHh4OU_E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# データの分割とアップサンプリング\n",
        "def split_and_upsample(X, y):\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "    df_train = pd.concat([X_train, y_train], axis=1)\n",
        "    df_normal_train = df_train[df_train[df_train.columns[-1]] == 1]\n",
        "    df_anomaly_train = df_train[df_train[df_train.columns[-1]] == -1]\n",
        "    df_anomaly_upsampled = resample(df_anomaly_train, replace=True, n_samples=len(df_normal_train), random_state=123)\n",
        "    df_upsampled_train = pd.concat([df_normal_train, df_anomaly_upsampled])\n",
        "    X_train_upsampled = df_upsampled_train.drop(df_upsampled_train.columns[-1], axis=1)\n",
        "    y_train_upsampled = df_upsampled_train[df_upsampled_train.columns[-1]]\n",
        "    return X_train_upsampled, y_train_upsampled, X_test, y_test"
      ],
      "metadata": {
        "id": "bR95Xd0fOW7E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# モデルの訓練\n",
        "def train_model(X_train_upsampled, y_train_upsampled):\n",
        "    lgbm = lgb.LGBMClassifier(max_depth=10, learning_rate=0.1, n_estimators=100)\n",
        "    lgbm.fit(X_train_upsampled, y_train_upsampled)\n",
        "    return lgbm"
      ],
      "metadata": {
        "id": "DZ5gEOCHOZsu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 予測と評価（時間計測付き）\n",
        "def predict_and_evaluate(model, X_test, y_test):\n",
        "    # 予測時間の計測を開始\n",
        "    start_time = time.time()\n",
        "    y_pred = model.predict(X_test)\n",
        "    # 予測時間の計測を終了\n",
        "    end_time = time.time()\n",
        "\n",
        "    # 予測にかかった時間を計算\n",
        "    elapsed_time = end_time - start_time\n",
        "\n",
        "    # 評価指標の計算\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    macro_f1 = f1_score(y_test, y_pred, average='macro')\n",
        "    weighted_f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "    mcc = matthews_corrcoef(y_test, y_pred)\n",
        "\n",
        "    return accuracy, macro_f1, weighted_f1, mcc, elapsed_time"
      ],
      "metadata": {
        "id": "J-Q9zWS_VkKy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# メイン関数\n",
        "def main():\n",
        "    # データパス\n",
        "    train_path = r\"/content/drive/MyDrive/Wafer/Wafer_TRAIN.xlsx\"\n",
        "    test_path = r\"/content/drive/MyDrive/Wafer/Wafer_TEST.xlsx\"\n",
        "\n",
        "    # データの読み込み\n",
        "    train_df, test_df = load_data(train_path, test_path)\n",
        "\n",
        "    # データの前処理\n",
        "    X, y = preprocess_data(train_df, test_df)\n",
        "\n",
        "    # データの分割とアップサンプリング\n",
        "    X_train_upsampled, y_train_upsampled, X_test, y_test = split_and_upsample(X, y)\n",
        "\n",
        "    # モデルの訓練\n",
        "    model = train_model(X_train_upsampled, y_train_upsampled)\n",
        "\n",
        "    # 予測と評価\n",
        "    accuracy, macro_f1, weighted_f1, mcc, elapsed_time = predict_and_evaluate(model, X_test, y_test)\n",
        "\n",
        "    # 結果の出力\n",
        "    print(f\"Accuracy: {accuracy}, Macro F1: {macro_f1}, Weighted F1: {weighted_f1}, MCC: {mcc}\")\n",
        "    print(f\"予測にかかった時間: {elapsed_time} 秒\")"
      ],
      "metadata": {
        "id": "5eJsmXSFVn7J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 10回計測する\n",
        "for i in range(10):\n",
        "    print(f\"{i+1}回目の計測\")\n",
        "    %memit main()\n",
        "    print(\"\\n\")"
      ],
      "metadata": {
        "id": "733WbxWMOe7l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d7dcdc6-bdf0-41c0-e644-57c8b85bf352"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1回目の計測\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 4468, number of negative: 4468\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018486 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 38759\n",
            "[LightGBM] [Info] Number of data points in the train set: 8936, number of used features: 152\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "Accuracy: 0.9976744186046511, Macro F1: 0.9936060430328174, Weighted F1: 0.9976815352966135, MCC: 0.9872412146086262\n",
            "予測にかかった時間: 0.011213541030883789 秒\n",
            "peak memory: 325.06 MiB, increment: 115.03 MiB\n",
            "\n",
            "\n",
            "2回目の計測\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 4468, number of negative: 4468\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.030117 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 38759\n",
            "[LightGBM] [Info] Number of data points in the train set: 8936, number of used features: 152\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "Accuracy: 0.9976744186046511, Macro F1: 0.9936060430328174, Weighted F1: 0.9976815352966135, MCC: 0.9872412146086262\n",
            "予測にかかった時間: 0.011627435684204102 秒\n",
            "peak memory: 334.64 MiB, increment: 62.18 MiB\n",
            "\n",
            "\n",
            "3回目の計測\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 4468, number of negative: 4468\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018525 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 38759\n",
            "[LightGBM] [Info] Number of data points in the train set: 8936, number of used features: 152\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "Accuracy: 0.9976744186046511, Macro F1: 0.9936060430328174, Weighted F1: 0.9976815352966135, MCC: 0.9872412146086262\n",
            "予測にかかった時間: 0.011646270751953125 秒\n",
            "peak memory: 332.71 MiB, increment: 64.09 MiB\n",
            "\n",
            "\n",
            "4回目の計測\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 4468, number of negative: 4468\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020728 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 38759\n",
            "[LightGBM] [Info] Number of data points in the train set: 8936, number of used features: 152\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "Accuracy: 0.9976744186046511, Macro F1: 0.9936060430328174, Weighted F1: 0.9976815352966135, MCC: 0.9872412146086262\n",
            "予測にかかった時間: 0.016948938369750977 秒\n",
            "peak memory: 332.35 MiB, increment: 44.72 MiB\n",
            "\n",
            "\n",
            "5回目の計測\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 4468, number of negative: 4468\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017987 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 38759\n",
            "[LightGBM] [Info] Number of data points in the train set: 8936, number of used features: 152\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "Accuracy: 0.9976744186046511, Macro F1: 0.9936060430328174, Weighted F1: 0.9976815352966135, MCC: 0.9872412146086262\n",
            "予測にかかった時間: 0.012371301651000977 秒\n",
            "peak memory: 336.22 MiB, increment: 49.98 MiB\n",
            "\n",
            "\n",
            "6回目の計測\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 4468, number of negative: 4468\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020435 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 38759\n",
            "[LightGBM] [Info] Number of data points in the train set: 8936, number of used features: 152\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "Accuracy: 0.9976744186046511, Macro F1: 0.9936060430328174, Weighted F1: 0.9976815352966135, MCC: 0.9872412146086262\n",
            "予測にかかった時間: 0.01692342758178711 秒\n",
            "peak memory: 332.42 MiB, increment: 46.16 MiB\n",
            "\n",
            "\n",
            "7回目の計測\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 4468, number of negative: 4468\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006608 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 38759\n",
            "[LightGBM] [Info] Number of data points in the train set: 8936, number of used features: 152\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "Accuracy: 0.9976744186046511, Macro F1: 0.9936060430328174, Weighted F1: 0.9976815352966135, MCC: 0.9872412146086262\n",
            "予測にかかった時間: 0.011781930923461914 秒\n",
            "peak memory: 333.58 MiB, increment: 53.09 MiB\n",
            "\n",
            "\n",
            "8回目の計測\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 4468, number of negative: 4468\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018831 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 38759\n",
            "[LightGBM] [Info] Number of data points in the train set: 8936, number of used features: 152\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "Accuracy: 0.9976744186046511, Macro F1: 0.9936060430328174, Weighted F1: 0.9976815352966135, MCC: 0.9872412146086262\n",
            "予測にかかった時間: 0.017162561416625977 秒\n",
            "peak memory: 333.54 MiB, increment: 47.23 MiB\n",
            "\n",
            "\n",
            "9回目の計測\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 4468, number of negative: 4468\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018424 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 38759\n",
            "[LightGBM] [Info] Number of data points in the train set: 8936, number of used features: 152\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "Accuracy: 0.9976744186046511, Macro F1: 0.9936060430328174, Weighted F1: 0.9976815352966135, MCC: 0.9872412146086262\n",
            "予測にかかった時間: 0.012226343154907227 秒\n",
            "peak memory: 337.58 MiB, increment: 49.13 MiB\n",
            "\n",
            "\n",
            "10回目の計測\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 4468, number of negative: 4468\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018558 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 38759\n",
            "[LightGBM] [Info] Number of data points in the train set: 8936, number of used features: 152\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "Accuracy: 0.9976744186046511, Macro F1: 0.9936060430328174, Weighted F1: 0.9976815352966135, MCC: 0.9872412146086262\n",
            "予測にかかった時間: 0.017612218856811523 秒\n",
            "peak memory: 333.36 MiB, increment: 44.89 MiB\n",
            "\n",
            "\n"
          ]
        }
      ]
    }
  ]
}